{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89f886e-f69f-484b-ac14-02c1b26abcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (2.37.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (1.34.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.63.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.19.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.12.14)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914a2063-a2a6-4b75-992a-4d5dc364ddfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fb7d9e-6f91-4960-ab73-3ef276773fad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from fastparquet) (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from fastparquet) (1.24.4)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from fastparquet) (2024.12.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from fastparquet) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.9.1 fastparquet-2024.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6cf2bb-68e7-4804-a2a0-5f2af7b972a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data saved in chunked Parquet files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Install fastparquet or pyarrow to enable .to_parquet\n",
    "# !pip install fastparquet\n",
    "\n",
    "# Define the path to the output Parquet file\n",
    "chunksize = 10000\n",
    "reader = pd.read_stata(\"gs://my-dataproc-staging-bucket/Data_input/Newnis2021_merged.dta\", chunksize=chunksize)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    # Example transform\n",
    "    # chunk[\"new_column\"] = chunk[\"existing_column\"] * 2\n",
    "    \n",
    "    # Write each chunk to a separate file\n",
    "    chunk.to_parquet(f\"transformed_data_v1_{i}.parquet\", index=False, engine=\"fastparquet\")\n",
    "\n",
    "print(\"Transformed data saved in chunked Parquet files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950f806-408c-48e9-acd9-9895308390f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make sure fastparquet is installed:\n",
    "# !pip install fastparquet\n",
    "\n",
    "output_parquet_path = \"transformed_data_v1.parquet\"\n",
    "chunksize = 10000\n",
    "\n",
    "reader = pd.read_stata(\"gs://my-dataproc-staging-bucket/Data_input/Newnis2021_merged.dta\", chunksize=chunksize)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    # Example transformation\n",
    "    # chunk[\"new_column\"] = chunk[\"existing_column\"] * 2\n",
    "    \n",
    "    # Write the first chunk\n",
    "    if i == 0:\n",
    "        chunk.to_parquet(output_parquet_path, engine=\"fastparquet\", index=False)\n",
    "    else:\n",
    "        # Append subsequent chunks into the same parquet dataset\n",
    "        chunk.to_parquet(output_parquet_path, engine=\"fastparquet\", index=False, append=True)\n",
    "\n",
    "print(f\"All chunks appended into parquet dataset: {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53794ea7-9297-459c-8a9f-11b0caa4a158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_parquet_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/pandas/io/parquet.py:403\u001b[0m, in \u001b[0;36mFastParquetImpl.read\u001b[0;34m(self, path, columns, filters, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     parquet_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mParquetFile(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparquet_kwargs)\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparquet_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/fastparquet/api.py:790\u001b[0m, in \u001b[0;36mParquetFile.to_pandas\u001b[0;34m(self, columns, categories, filters, index, row_filter, dtypes)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     parts \u001b[38;5;241m=\u001b[39m {name: (v \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-catdef\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    788\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m v[start:start \u001b[38;5;241m+\u001b[39m thislen])\n\u001b[1;32m    789\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m (name, v) \u001b[38;5;129;01min\u001b[39;00m views\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_row_group_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                             \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrow_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     start \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m thislen\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/fastparquet/api.py:388\u001b[0m, in \u001b[0;36mParquetFile.read_row_group_file\u001b[0;34m(self, rg, columns, categories, index, assign, partition_meta, row_filter, infile)\u001b[0m\n\u001b[1;32m    385\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    386\u001b[0m f \u001b[38;5;241m=\u001b[39m infile \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(fn, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 388\u001b[0m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_row_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselfmade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselfmade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_scheme\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_filter\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/fastparquet/core.py:644\u001b[0m, in \u001b[0;36mread_row_group\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, index, assign, scheme, partition_meta, row_filter)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m assign \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoing with pre-allocation!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 644\u001b[0m \u001b[43mread_row_group_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_helper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselfmade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m cats:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cat \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m assign:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;66;03m# do no need to have partition columns in output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/fastparquet/core.py:615\u001b[0m, in \u001b[0;36mread_row_group_arrays\u001b[0;34m(file, rg, columns, categories, schema_helper, cats, selfmade, assign, row_filter)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    613\u001b[0m remains\u001b[38;5;241m.\u001b[39mdiscard(name)\n\u001b[0;32m--> 615\u001b[0m \u001b[43mread_col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_helper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-catdef\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m         \u001b[49m\u001b[43mselfmade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselfmade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcatdef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-catdef\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m         \u001b[49m\u001b[43mrow_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_map_like(schema_helper, column):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# TODO: could be done in fast loop in _assemble_objects?\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m maps:\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/fastparquet/core.py:561\u001b[0m, in \u001b[0;36mread_col\u001b[0;34m(column, schema_helper, infile, use_cat, selfmade, assign, catdef, row_filter)\u001b[0m\n\u001b[1;32m    559\u001b[0m     part \u001b[38;5;241m=\u001b[39m part\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m part\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 561\u001b[0m     \u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdefi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_defi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m my_nan\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_cat:\n\u001b[1;32m    563\u001b[0m     part[defi \u001b[38;5;241m==\u001b[39m max_defi] \u001b[38;5;241m=\u001b[39m dic[val]\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(output_parquet_path)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c986511-a33d-4bc3-b6e2-6b6ce10c7a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data saved to transformed_data_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the output CSV file\n",
    "output_csv_path = \"transformed_data_v1.csv\"\n",
    "\n",
    "# Read the .dta file in chunks\n",
    "chunksize = 10000  # Adjust the chunk size based on your memory capacity\n",
    "reader = pd.read_stata(\"gs://my-dataproc-staging-bucket/Data_input/Newnis2021_merged.dta\", chunksize=chunksize)\n",
    "\n",
    "# Process and save each chunk\n",
    "for i, chunk in enumerate(reader):\n",
    "    # Apply your transformations here\n",
    "    # Example: chunk['new_column'] = chunk['existing_column'] * 2\n",
    "    \n",
    "    # Save the transformed chunk to CSV\n",
    "    if i == 0:\n",
    "        chunk.to_csv(output_csv_path, index=False, mode='w', header=True)\n",
    "    else:\n",
    "        chunk.to_csv(output_csv_path, index=False, mode='a', header=False)\n",
    "\n",
    "print(f\"Transformed data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a6ab13-45d5-46e3-9abb-660095e29484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_17927/3756618609.py:1: DtypeWarning: Columns (68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(output_csv_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOSP_NIS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CCR_NIS</th>\n",
       "      <th>WAGEINDEX</th>\n",
       "      <th>DISCWT</th>\n",
       "      <th>HOSP_BEDSIZE</th>\n",
       "      <th>HOSP_DIVISION</th>\n",
       "      <th>HOSP_LOCTEACH</th>\n",
       "      <th>HOSP_REGION</th>\n",
       "      <th>H_CONTRL</th>\n",
       "      <th>...</th>\n",
       "      <th>new</th>\n",
       "      <th>fy2021finalpostacutedrg</th>\n",
       "      <th>fy2021finalspecialpaydrg</th>\n",
       "      <th>mdc</th>\n",
       "      <th>type</th>\n",
       "      <th>msdrgtitle</th>\n",
       "      <th>weights</th>\n",
       "      <th>geometricmeanlos</th>\n",
       "      <th>arithmeticmeanlos</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50385</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.887</td>\n",
       "      <td>5.000010</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50378</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.948</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30454</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.940</td>\n",
       "      <td>5.000006</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50568</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.440</td>\n",
       "      <td>1.124</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70434</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.929</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10100</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.278</td>\n",
       "      <td>1.099</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20276</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.065</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60251</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20367</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1.363</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30487</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.902</td>\n",
       "      <td>5.000006</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>PRE</td>\n",
       "      <td>SURG</td>\n",
       "      <td>HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...</td>\n",
       "      <td>28.9652</td>\n",
       "      <td>30.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>Matched (3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOSP_NIS  YEAR  CCR_NIS  WAGEINDEX    DISCWT  HOSP_BEDSIZE  HOSP_DIVISION  \\\n",
       "0     50385  2021    0.327      0.887  5.000010             3              5   \n",
       "1     50378  2021    0.196      0.948  4.999997             3              5   \n",
       "2     30454  2021    0.252      0.940  5.000006             3              3   \n",
       "3     50568  2021    0.440      1.124  4.999997             3              5   \n",
       "4     70434  2021    0.100      0.929  5.000000             1              7   \n",
       "5     10100  2021    0.278      1.099  5.000000             2              1   \n",
       "6     20276  2021    0.101      1.065  4.999997             3              2   \n",
       "7     60251  2021    0.217      0.895  5.000000             2              6   \n",
       "8     20367  2021    0.214      1.363  4.999997             3              2   \n",
       "9     30487  2021    0.400      0.902  5.000006             3              3   \n",
       "\n",
       "   HOSP_LOCTEACH  HOSP_REGION  H_CONTRL  ...   new  fy2021finalpostacutedrg  \\\n",
       "0              3            3         1  ...   1.0                       No   \n",
       "1              3            3         2  ...   2.0                       No   \n",
       "2              3            2         2  ...   3.0                       No   \n",
       "3              3            3         2  ...   4.0                       No   \n",
       "4              3            3         3  ...   5.0                       No   \n",
       "5              3            1         2  ...   6.0                       No   \n",
       "6              3            1         2  ...   7.0                       No   \n",
       "7              3            3         2  ...   8.0                       No   \n",
       "8              3            1         2  ...   9.0                       No   \n",
       "9              3            2         2  ...  10.0                       No   \n",
       "\n",
       "   fy2021finalspecialpaydrg  mdc  type  \\\n",
       "0                        No  PRE  SURG   \n",
       "1                        No  PRE  SURG   \n",
       "2                        No  PRE  SURG   \n",
       "3                        No  PRE  SURG   \n",
       "4                        No  PRE  SURG   \n",
       "5                        No  PRE  SURG   \n",
       "6                        No  PRE  SURG   \n",
       "7                        No  PRE  SURG   \n",
       "8                        No  PRE  SURG   \n",
       "9                        No  PRE  SURG   \n",
       "\n",
       "                                          msdrgtitle  weights  \\\n",
       "0  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "1  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "2  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "3  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "4  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "5  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "6  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "7  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "8  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "9  HEART TRANSPLANT OR IMPLANT OF HEART ASSIST SY...  28.9652   \n",
       "\n",
       "   geometricmeanlos  arithmeticmeanlos       _merge  \n",
       "0              30.2               39.2  Matched (3)  \n",
       "1              30.2               39.2  Matched (3)  \n",
       "2              30.2               39.2  Matched (3)  \n",
       "3              30.2               39.2  Matched (3)  \n",
       "4              30.2               39.2  Matched (3)  \n",
       "5              30.2               39.2  Matched (3)  \n",
       "6              30.2               39.2  Matched (3)  \n",
       "7              30.2               39.2  Matched (3)  \n",
       "8              30.2               39.2  Matched (3)  \n",
       "9              30.2               39.2  Matched (3)  \n",
       "\n",
       "[10 rows x 75 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(output_csv_path)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3951e-2c77-44b0-8a93-8814479ecff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
